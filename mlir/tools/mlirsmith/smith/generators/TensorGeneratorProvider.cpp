//
// Created by Stan Wang on 2022/12/23.
//
#include "include/smith/TypeGeneration.h"
#include "include/smith/RegionGeneration.h"
#include "mlir/Dialect/LLVMIR/LLVMOps.h.inc"
#include "include/smith/generators/OpGeneration.h"

OpGenerator tensorCastGenerator() {
  return [](OpBuilder &builder, Location loc, OpRegion &region) {
    auto operandCandidates = region.pool.searchCandidatesFrom(
        {PoolType::StaticShapedTensor, PoolType::DynamicShapedTensor},
        emptyFilter());
    if (operandCandidates.empty()) {
      operandCandidates.push_back(region.pool.generateRankedTensor(
          builder, loc, randomRankedTensorType(builder.getContext())));
    }
    auto src = sampleTypedValueFrom(operandCandidates, "tensor.cast");
    auto srcTy = mlir::dyn_cast<RankedTensorType>(src.type);
    SmallVector<int64_t> newShape;
    if (srcTy.hasStaticShape()) {
      for (int i = 0; i < srcTy.getRank(); ++i) {
        newShape.push_back(ShapedType::kDynamic);
      }
    } else {
      for (int i = 0; i < srcTy.getRank(); ++i) {
        if (srcTy.isDynamicDim(i)) {
          newShape.push_back(dimPool[UR(dimPool.size())]);
        } else {
          newShape.push_back(srcTy.getDimSize(i));
        }
      }
    }

    auto destTy = RankedTensorType::get(newShape, srcTy.getElementType());
    auto res = tensor::CastOp::create(builder, loc, destTy, src.val);
    // auto res = tensor::CastOp::create(builder, loc, destTy, src.val);
    region.pool.addDynamicShapedTensor(TypeValue(destTy, res), "tensor.cast");
    return res.getOperation();
  };
}

static RankedTensorType
computeTensorReshapeCollapsedType(RankedTensorType type,
                                  ArrayRef<AffineMap> reassociation) {
  auto shape = type.getShape();
  SmallVector<int64_t, 4> newShape;
  newShape.reserve(reassociation.size());

  // Use the fact that reassociation is valid to simplify the logic: only use
  // each map's rank.
  assert(isReassociationValid(reassociation) && "invalid reassociation");
  unsigned currentDim = 0;
  for (AffineMap m : reassociation) {
    unsigned dim = m.getNumResults();
    auto band = shape.slice(currentDim, dim);
    int64_t size = 1;
    if (llvm::is_contained(band, ShapedType::kDynamic))
      size = ShapedType::kDynamic;
    else
      for (unsigned d = 0; d < dim; ++d)
        size *= shape[currentDim + d];
    newShape.push_back(size);
    currentDim += dim;
  }

  return RankedTensorType::get(newShape, type.getElementType());
}

OpGenerator tensorCollapseShapeGenerator() {
  return [](OpBuilder &builder, Location loc, OpRegion &region) {
    auto candidates = region.pool.searchCandidatesFrom(
        {PoolType::StaticShapedTensor, PoolType::DynamicShapedTensor},
        [&](TypeValue typeValue) {
          return mlir::dyn_cast<TensorType>(typeValue.type).getRank() >= 2;
        });
    if (candidates.empty()) {
      SmallVector<int64_t> shape;
      shape.push_back(2);
      shape.push_back(2);
      auto type = randomIntOrFloatType(builder.getContext());
      candidates.push_back(region.pool.generateStaticShapedTensor(
          builder, loc, RankedTensorType::get(shape, type)));
    }
    auto source = sampleTypedValueFrom(candidates, "tensor.collapse_shape");
    auto srcTy = mlir::dyn_cast<RankedTensorType>(source.type);
    SmallVector<ReassociationIndices> reIdxes;
    reIdxes.push_back({0, 1});
    for (int i = 2; i < srcTy.getRank(); ++i) {
      ReassociationIndices indices;
      indices.push_back(i);
      if (UR(2) && srcTy.getRank() - i > 1) {
        indices.push_back(i + 1);
        i++;
      }
      reIdxes.push_back(indices);
    }
    auto res =
        tensor::CollapseShapeOp::create(builder, loc, source.val, reIdxes);
    // auto res = tensor::CollapseShapeOp::create(builder, loc, source.val,
    // reIdxes);
    auto resultType = computeTensorReshapeCollapsedType(
        srcTy, getSymbolLessAffineMaps(convertReassociationIndicesToExprs(
                   builder.getContext(), reIdxes)));
    auto tVal = TypeValue(resultType, res);
    region.pool.addRankedTensor(tVal, "tensor.collapse_shape");
    return res.getOperation();
  };
}

OpGenerator tensorDimGenerator() {
  return [](OpBuilder &builder, Location loc, OpRegion &region) {
    auto candidates = region.pool.searchCandidatesFrom(
        {PoolType::StaticShapedTensor, PoolType::DynamicShapedTensor},
        [](TypeValue tval) {
          return mlir::dyn_cast<RankedTensorType>(tval.type).getRank() > 0;
        });
    if (candidates.empty()) {
      candidates.push_back(region.pool.generateRankedTensor(
          builder, loc, randomRankedTensorType(builder.getContext())));
    }
    auto source = sampleTypedValueFrom(candidates, "tensor.dim");
    auto srcTy = mlir::dyn_cast<RankedTensorType>(source.type);
    auto num = UR(srcTy.getRank());
    auto idx = region.pool.getConstantIndex(builder, loc, num);
    assert(llvm::detail::isPresent(idx));
    auto res = tensor::DimOp::create(builder, loc, source.val, idx);
    // auto res = tensor::DimOp::create(builder, loc, source.val, idx);
    region.pool.addIndex(TypeValue(IndexType::get(builder.getContext()), res),
                         "tensor.dim");
    return res.getOperation();
  };
}

OpGenerator tensorEmptyGenerator() {
  return [](OpBuilder &builder, Location loc, OpRegion &region) {
    if (UR(2)) {
      auto tensorTy = mlir::dyn_cast<RankedTensorType>(
          randomStaticShapedTensorType(builder.getContext()));
      auto res = tensor::EmptyOp::create(builder, loc, tensorTy.getShape(),
                                         tensorTy.getElementType());
      // auto res = tensor::EmptyOp::create(builder, loc, tensorTy.getShape(),
      // tensorTy.getElementType());

      region.pool.addStaticShapedTensor(TypeValue(tensorTy, res),
                                        "tensor.empty");
      return res.getOperation();
    } else {
      auto shape = shapePool[UR(shapePool.size())];
      SmallVector<Value> dynamicSizes;
      for (size_t i = 0; i < shape.size(); ++i) {
        if (UR(2)) {
          shape[i] = ShapedType::kDynamic;
          dynamicSizes.push_back(
              sampleTypedValueFrom(
                  region.pool.getCandidatesFromIndex(builder, loc),
                  "tensor.empty")
                  .val);
        }
      }
      auto tensorTy = RankedTensorType::get(
          shape, randomIntOrFloatType(builder.getContext()));
      return tensor::EmptyOp::create(builder, loc, tensorTy,
                                     ValueRange(dynamicSizes))
          .getOperation();
      // return tensor::EmptyOp::create(builder, loc, tensorTy,
      // ValueRange(dynamicSizes)).getOperation();
    }
  };
}

OpGenerator tensorExpandShapeGenerator() {
  return [](OpBuilder &builder, Location loc, OpRegion &region) {
    auto candidates = region.pool.searchCandidatesFrom(
        {PoolType::StaticShapedTensor, PoolType::DynamicShapedTensor},
        [&](TypeValue typeValue) {
          auto tensorTy = mlir::dyn_cast<TensorType>(typeValue.type);
          return tensorTy.getRank() > 0 &&
                 !tensorTy.isDynamicDim(tensorTy.getRank() - 1);
        });

    auto source = sampleTypedValueFrom(candidates, "tensor.expand_shape");
    auto srcTy = mlir::dyn_cast<RankedTensorType>(source.type);

    SmallVector<int64_t> newShape;
    SmallVector<ReassociationIndices> reassociation;
    int idx = 0;
    for (int i = 0; i < srcTy.getRank() - 1; ++i) {
      ReassociationIndices indices;
      indices.push_back(i);
      reassociation.push_back(indices);
      newShape.push_back(srcTy.getDimSize(i));
    }
    ReassociationIndices indices;
    indices.push_back(srcTy.getRank() - 1);
    indices.push_back(srcTy.getRank());
    reassociation.push_back(indices);

    newShape.push_back(srcTy.getDimSize(srcTy.getRank() - 1));
    newShape.push_back(1);
    auto resTy = RankedTensorType::get(newShape, srcTy.getElementType());
    // auto res = tensor::ExpandShapeOp::create(builder, 
    //     loc, resTy, source.val, reassociation,
    //     SmallVector<NamedAttribute>());
    // auto res = tensor::ExpandShapeOp::create(builder, 
    //     loc, resTy, source.val, reassociation);
    auto res = tensor::ExpandShapeOp::create(builder, loc, resTy, source.val,
                                             reassociation);
    region.pool.addRankedTensor(TypeValue(resTy, res), "tensor.expand_shape");
    return res.getOperation();
  };
}

OpGenerator tensorExtractGenerator() {
  return [](OpBuilder &builder, Location loc, OpRegion &region) {
    auto candidates = region.pool.searchCandidatesFrom(
        {PoolType::DynamicShapedTensor, PoolType::StaticShapedTensor},
        [&](TypeValue) { return true; });
    if (candidates.empty()) {
      candidates.push_back(region.pool.generateDynamicShapedTensor(
          builder, loc,
          UR(2) ? randomStaticShapedTensorType(builder.getContext())
                : randomDynamicShapedTensorType(builder.getContext())));
    }
    auto source = sampleTypedValueFrom(candidates, "tensor.extract");
    auto srcTy = mlir::dyn_cast<ShapedType>(source.type);
    auto indices = region.pool.randomIndicesForShapedType(srcTy, builder, loc);
    // auto res = tensor::ExtractOp::create(builder, loc, source.val, indices);
    auto res = tensor::ExtractOp::create(builder, loc, source.val, indices);
    region.pool.addElement(TypeValue(srcTy.getElementType(), res),
                           "tensor.extract");

    return res.getOperation();
  };
}

OpGenerator tensorExtractSliceGenerator() {
  return [](OpBuilder &builder, Location loc, OpRegion &region) {
    auto srcCandidates = region.pool.searchCandidatesFrom(
        {PoolType::StaticShapedTensor, PoolType::DynamicShapedTensor},
        [](TypeValue tval) {
          return mlir::dyn_cast<RankedTensorType>(tval.type).getRank() > 0;
        });
    if (srcCandidates.empty()) {
      srcCandidates.push_back(region.pool.generateRankedTensor(
          builder, loc, randomRankedTensorType(builder.getContext())));
    }
    auto src = sampleTypedValueFrom(srcCandidates, "tensor.extract_slice");
    auto srcTy = mlir::dyn_cast<RankedTensorType>(src.val.getType());

    SmallVector<OpFoldResult> offsets;
    SmallVector<OpFoldResult> sizes;
    SmallVector<OpFoldResult> strides;

    auto idxes = region.pool.getCandidatesFromIndex(builder, loc);
    for (int i = 0; i < srcTy.getRank(); ++i) {
      offsets.push_back(
          sampleTypedValueFrom(idxes, "tensor.extract_slice").val);
      sizes.push_back(sampleTypedValueFrom(idxes, "tensor.extract_slice").val);
      strides.push_back(
          sampleTypedValueFrom(idxes, "tensor.extract_slice").val);
    }

    auto destTy = tensor::ExtractSliceOp::inferCanonicalRankReducedResultType(
        srcTy.getRank() - 1, srcTy, sizes, offsets, strides);
    // auto op = tensor::ExtractSliceOp::create(builder, loc, destTy, src.val,
    //                                                  offsets, sizes,
    //                                                  strides);
    auto op = tensor::ExtractSliceOp::create(builder, loc, destTy, src.val,
                                             offsets, sizes, strides);
    return op.getOperation();
  };
}

OpGenerator tensorFromElementsGenerator() {
  return [](OpBuilder &builder, Location loc, OpRegion &region) {
    auto elemTy = randomIntOrFloatType(builder.getContext());
    auto candidates = region.pool.searchCandidatesFrom(
        {PoolType::IntOrFloat},
        [&](TypeValue tVal) { return tVal.type == elemTy; });
    if (candidates.empty()) {
      candidates.push_back(
          region.pool.generateTypedValue(builder, loc, elemTy));
    }
    auto tensorTy = randomStaticShapedTensorType(elemTy);
    int elemNum = 1;
    for (int i = 0; i < tensorTy.getRank(); ++i) {
      elemNum = elemNum * tensorTy.getDimSize(i);
    }
    SmallVector<Value> elements;
    for (int i = 0; i < elemNum; ++i) {
      elements.push_back(
          sampleTypedValueFrom(candidates, "tensor.from_elements").val);
    }
    // auto res = tensor::FromElementsOp::create(builder, loc, tensorTy,
    //                                                   ValueRange(elements));
    auto res = tensor::FromElementsOp::create(builder, loc, tensorTy,
                                              ValueRange(elements));
    region.pool.addStaticShapedTensor(TypeValue(tensorTy, res),
                                      "tensor.from_elements");
    return res.getOperation();
  };
}

// OpGenerator tensorGatherGenerator() {
// }

OpGenerator tensorGenerateGenerator() {
  return [](OpBuilder &builder, Location loc, OpRegion &parent) {
    auto opFilter = OpNameFilter(opsForTensorGenerate);
    auto dynTenTy = randomDynamicShapedTensorType(builder.getContext());
    auto idxCandidates = parent.pool.getCandidatesFromIndex(builder, loc);
    SmallVector<Value> dynamicSizes;
    for (int i = 0; i < dynTenTy.getNumDynamicDims(); ++i) {
      dynamicSizes.push_back(
          sampleTypedValueFrom(idxCandidates, "tensor.generate").val);
    }

    auto res = tensor::GenerateOp::create(
        builder, loc, dynTenTy, dynamicSizes,
        [&](OpBuilder &b, Location loc, ValueRange args) {
          
          
          b.setInsertionPointToEnd(b.getBlock());


          auto region =
              OpRegion("tensor.generate", parent.depth + 1, parent.cur_child);
          region.pool.merge(parent.pool);
          for (auto val : args) {
            region.pool.addIndex(TypeValue(b.getIndexType(), val),
                                 "args(tensor.generate)");
          }
          RegionGen regionGen(&region, {opFilter});
          regionGen.apply(b, loc, 4);

          auto retCandidates = region.pool.searchCandidatesFrom(
              {PoolType::IntOrFloat}, [&](TypeValue typeValue) {
                return typeValue.type == dynTenTy.getElementType();
              });
          if (retCandidates.empty()) {
            retCandidates.push_back(region.pool.generateElement(
                b, loc, dynTenTy.getElementType()));
          }
          auto ret = sampleTypedValueFrom(retCandidates, "tensor.yield");
          tensor::YieldOp::create(b, loc, ret.val);
        });

    parent.pool.addRankedTensor(TypeValue(dynTenTy, res), "tensor.generate");
    return res.getOperation();
  };
}

OpGenerator tensorInsertGenerator() {

  return [](OpBuilder &builder, Location loc, OpRegion &region) {
    auto candidates = region.pool.searchCandidatesFrom(
        {PoolType::DynamicShapedTensor, PoolType::StaticShapedTensor},
        [&](TypeValue) { return true; });
    if (candidates.empty()) {
      candidates.push_back(region.pool.generateDynamicShapedTensor(
          builder, loc,
          UR(2) ? randomStaticShapedTensorType(builder.getContext())
                : randomDynamicShapedTensorType(builder.getContext())));
    }
    auto source = sampleTypedValueFrom(candidates, "tensor.insert");
    auto srcTy = mlir::dyn_cast<ShapedType>(source.type);
    auto elemTy = srcTy.getElementType();
    auto elemCandidates = region.pool.searchCandidatesFrom(
        {PoolType::IntOrFloat, PoolType::Index},
        [&](TypeValue tval) { return tval.type == elemTy; });
    if (elemCandidates.empty()) {
      elemCandidates.push_back(
          region.pool.generateTypedValue(builder, loc, elemTy));
    }
    auto elem = sampleTypedValueFrom(elemCandidates, "tensor.insert");
    auto indices = region.pool.randomIndicesForShapedType(srcTy, builder, loc);
    return tensor::InsertOp::create(builder, loc, elem.val, source.val, indices)
        .getOperation();
  };
}

OpGenerator tensorInsertSliceGenerator() {
  return [](OpBuilder &builder, Location loc, OpRegion &region) {
    auto destCandidates = region.pool.searchCandidatesFrom(
        {PoolType::StaticShapedTensor, PoolType::DynamicShapedTensor},
        [](TypeValue tval) {
          return mlir::dyn_cast<RankedTensorType>(tval.type).getRank() > 0;
        });
    auto dest = sampleTypedValueFrom(destCandidates, "tensor.insert_slice");
    auto destTy = mlir::dyn_cast<RankedTensorType>(dest.val.getType());

    SmallVector<OpFoldResult> offsets;
    SmallVector<OpFoldResult> sizes;
    SmallVector<OpFoldResult> strides;

    auto idxes = region.pool.getCandidatesFromIndex(builder, loc);
    for (int i = 0; i < destTy.getRank(); ++i) {
      offsets.push_back(sampleTypedValueFrom(idxes, "tensor.insert_slice").val);
      sizes.push_back(sampleTypedValueFrom(idxes, "tensor.insert_slice").val);
      strides.push_back(sampleTypedValueFrom(idxes, "tensor.insert_slice").val);
    }

    auto srcTy = tensor::ExtractSliceOp::inferCanonicalRankReducedResultType(
        destTy.getRank() - 1, destTy, sizes, offsets, strides);
    auto srcCandidates = region.pool.searchCandidatesFrom(
        {PoolType::StaticShapedTensor, PoolType::DynamicShapedTensor},
        typeEquivalentFilter(srcTy));
    if (srcCandidates.empty()) {
      srcCandidates.push_back(
          region.pool.generateRankedTensor(builder, loc, srcTy));
    }
    auto src = sampleTypedValueFrom(srcCandidates, "tensor.insert_slice");

    return tensor::InsertSliceOp::create(builder, loc, src.val, dest.val,
                                         offsets, sizes, strides)
        .getOperation();
  };
}

// This operation has been moved to linalg
OpGenerator tensorPackGenerator() {
  return [](OpBuilder &builder, Location loc, OpRegion &region) {
    auto candidates = region.pool.getCandidatesFromStaticShapedTensor(
        builder, loc, randomStaticShapedTensorType(builder.getContext()));
    auto src = sampleTypedValueFrom(candidates, "linalg.pack");  // tensor.pack
    auto srcTy = mlir::dyn_cast<TensorType>(src.type);
    auto padCandidates = region.pool.searchCandidatesFrom(
        {PoolType::IntOrFloat, PoolType::Index},
        [&](TypeValue tVal) { return tVal.type == srcTy.getElementType(); });
    if (padCandidates.empty()) {
      padCandidates.push_back(
          region.pool.generateElement(builder, loc, srcTy.getElementType()));
    }
    auto pad = sampleTypedValueFrom(padCandidates, "linalg.pack");

    SmallVector<int64_t> innerDimsPos;
    SmallVector<int64_t> innerTileInts;
    SmallVector<int64_t> outerDimsPos;
    SmallVector<int64_t> newShape;
    for (int i = 0; i < srcTy.getRank(); ++i) {
      innerDimsPos.push_back(i);
      if (srcTy.getDimSize(i) > 1) {
        innerTileInts.push_back(2);
        newShape.push_back(2);
      } else {
        innerTileInts.push_back(1);
        newShape.push_back(1);
      }
      outerDimsPos.push_back(i);
    }
    SmallVector<OpFoldResult> innerTiles;
    for (int i = 0; i < srcTy.getRank(); ++i) {
      newShape.insert(newShape.begin() + i,
                      (int)ceil(srcTy.getDimSize(i) * 1.0 /
                      innerTileInts[i]));
      innerTiles.push_back(region.pool.constantIndices[innerTileInts[i]]);
    }
    auto destTy = RankedTensorType::get(newShape, srcTy.getElementType());
    auto dest = region.pool.generateStaticShapedTensor(builder, loc, destTy);

    return mlir::linalg::PackOp::create(builder, loc, src.val, dest.val, innerDimsPos, innerTiles, std::optional<Value>(pad.val), outerDimsPos).getOperation();
  };
}

OpGenerator tensorRankGenerator() {

  return [](OpBuilder &builder, Location loc, OpRegion &region) {
    auto candidates = region.pool.searchCandidatesFrom(
        {PoolType::StaticShapedTensor, PoolType::DynamicShapedTensor},
        [&](TypeValue) { return true; });
    if (candidates.empty()) {
      candidates.push_back(region.pool.generateStaticShapedTensor(
          builder, loc, randomStaticShapedTensorType(builder.getContext())));
    }
    auto source = sampleTypedValueFrom(candidates, "tensor.rank");
    // auto res = tensor::RankOp::create(builder, loc, source.val);
    auto res = tensor::RankOp::create(builder, loc, source.val);
    region.pool.addIndex(TypeValue(builder.getIndexType(), res), "tensor.rank");
    return res.getOperation();
  };
}

OpGenerator tensorScatterGenerator() {
  return [](OpBuilder &builder, Location loc, OpRegion &region) {
    auto candidates = region.pool.getCandidatesFromStaticShapedTensor(
        builder, loc, randomStaticShapedTensorType(builder.getContext()));
    auto dest = sampleTypedValueFrom(candidates, "tensor.scatter");
    auto destTy = mlir::dyn_cast<RankedTensorType>(dest.type);

    SmallVector<int64_t> srcShape;
    SmallVector<int64_t> indicesShape;
    auto dim0 = dimPool[UR(dimPool.size())];
    srcShape.push_back(dim0);
    indicesShape.push_back(dim0);
    indicesShape.push_back(destTy.getRank());
    SmallVector<int64_t> scatterDims;
    for (int i = 0; i < destTy.getRank(); ++i) {
      srcShape.push_back(1);
      scatterDims.push_back(i);
    }

    auto srcTy = RankedTensorType::get(srcShape, destTy.getElementType());
    auto indicesTy =
        RankedTensorType::get(indicesShape, builder.getIndexType());

    auto srcCandidates = region.pool.searchCandidatesFrom(
        {PoolType::StaticShapedTensor},
        [&](TypeValue tval) { return tval.type == srcTy; });
    if (srcCandidates.empty()) {
      srcCandidates.push_back(
          region.pool.generateStaticShapedTensor(builder, loc, srcTy));
    }
    auto src = sampleTypedValueFrom(srcCandidates, "tensor.scatter");

    auto indicesCandidates = region.pool.searchCandidatesFrom(
        {PoolType::StaticShapedTensor},
        [&](TypeValue tval) { return tval.type == indicesTy; });
    if (indicesCandidates.empty()) {
      indicesCandidates.push_back(
          region.pool.generateStaticShapedTensor(builder, loc, indicesTy));
    }
    auto indices = sampleTypedValueFrom(indicesCandidates, "tensor.scatter");

    // auto res = tensor::ScatterOp::create(builder, 
    //     loc, destTy, src.val, dest.val, indices.val, scatterDims, true);
    auto res =
        tensor::ScatterOp::create(builder, loc, destTy, src.val, dest.val,
                                    indices.val, scatterDims, true);
    region.pool.addRankedTensor(TypeValue(res.getType(), res),
                                "tensor.scatter");
    return res.getOperation();
  };
}

OpGenerator tensorSplatGenerator() {
  return [](OpBuilder &builder, Location loc, OpRegion &region) {
    auto candidates = region.pool.getCandidatesFromIntOrFloats(
        builder, loc, randomIntOrFloatType(builder.getContext()));
    auto elem = sampleTypedValueFrom(candidates, "tensor.splat");
    auto tensorTy = randomStaticShapedTensorType(elem.type);

    // auto res = tensor::SplatOp::create(builder, loc, elem.val, tensorTy);
    auto res = tensor::SplatOp::create(builder, loc, elem.val, tensorTy);
    region.pool.addStaticShapedTensor(TypeValue(tensorTy, res), "tensor.splat");
    return res.getOperation();
  };
}

// This operation has been removed to linalg dialect.
OpGenerator tensorUnpackGenerator() {
  return [](OpBuilder &builder, Location loc, OpRegion &region) {
    auto candidates = region.pool.searchCandidatesFrom(
        {PoolType::StaticShapedTensor}, [&](TypeValue tVal) {
          return mlir::dyn_cast<RankedTensorType>(tVal.type).getRank() % 2 == 0;
        });
    if (candidates.empty()) {
      SmallVector<int64_t> shape;
      shape.push_back(2);
      shape.push_back(2);
      auto tensorTy = RankedTensorType::get(
          shape, randomIntOrFloatType(builder.getContext()));
      candidates.push_back(
          region.pool.generateStaticShapedTensor(builder, loc, tensorTy));
    }
    auto source = sampleTypedValueFrom(candidates, "linalg.unpack");
    auto srcTy = mlir::dyn_cast<RankedTensorType>(source.type);

    SmallVector<int64_t> newShape;
    SmallVector<int64_t> innerDimsPos;
    SmallVector<OpFoldResult> innerTiles;
    SmallVector<int64_t> outerDimsPerm;
    for (int i = 0; i < srcTy.getRank() / 2; ++i) {

      newShape.push_back(srcTy.getDimSize(i) *
                         srcTy.getDimSize(i + srcTy.getRank() / 2));
      innerDimsPos.push_back(i);
      int64_t dimSize = srcTy.getDimSize(i + srcTy.getRank() / 2);
      /**
       * when dimension is dynamic, getDimSize function will return a negative
       * value. This will cause the inner_tiles to be a negative invalid value.
       * However, attributes are constant value during the compile-time, while
       * the dynamic dimension is a runtime value. Thus we use 0 as default, if
       * the corresponding dimension is dynamic.
       */
      int64_t newDimSize = dimSize >= 0 ? dimSize : 0;

      // mlir::Value innerTile = index::ConstantOp::create(builder, loc,
      // INT64_MIN).getResult();
      mlir::Value innerTile =
          index::ConstantOp::create(builder, loc, INT64_MIN).getResult();

      innerTiles.push_back(innerTile);
      outerDimsPerm.push_back(i);
    }
    auto destTy = RankedTensorType::get(newShape, srcTy.getElementType());
    auto destCandidates = region.pool.searchCandidatesFrom(
        {PoolType::StaticShapedTensor},
        [&](TypeValue tVal) { return tVal.type == destTy; });
    if (destCandidates.empty()) {
      destCandidates.push_back(
          region.pool.generateStaticShapedTensor(builder, loc, destTy));
    }
    auto dest = sampleTypedValueFrom(destCandidates, "linalg.unpack");
    // return builder
    //     .create<tensor::UnPackOp>(loc, source.val, dest.val, innerDimsPos,
    //     innerTiles, outerDimsPerm) .getOperation();
    return mlir::linalg::UnPackOp::create(builder, loc, source.val, dest.val, innerDimsPos, innerTiles, outerDimsPerm).getOperation();
  };
}